<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LiDAR on YUJIE HE</title>
    <link>https://yujie-he.github.io/tags/lidar/</link>
    <description>Recent content in LiDAR on YUJIE HE</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Last updated on Mar 3, 2022 Â· Yujie HE &amp;copy; 2019 - 2022</copyright>
    <lastBuildDate>Tue, 01 Feb 2022 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://yujie-he.github.io/tags/lidar/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Multi-modal pedestrian behavior analysis for Qolo robot</title>
      <link>https://yujie-he.github.io/project/2021-qolo-pedestrian-analysis/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2021-qolo-pedestrian-analysis/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Research Assistant&lt;/strong&gt; at &lt;a href=&#34;https://lasa.epfl.ch/&#34; target=&#34;_blank&#34;&gt;Learning Algorithms and  Systems Laboratory (LASA)&lt;/a&gt;, EPFL since &lt;em&gt;Oct. 2021&lt;/em&gt;
Supervisor: &lt;a href=&#34;https://people.epfl.ch/diego.paez&#34; target=&#34;_blank&#34;&gt;Dr. Diego Felipe Paez Granados&lt;/a&gt;, and &lt;a href=&#34;https://people.epfl.ch/aude.billard?lang=en&#34; target=&#34;_blank&#34;&gt;Prof. Aude Billard&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
  &lt;img src=&#34;./qolo_tracking.gif&#34; alt=&#34;Qolo trajectory and tracked pedestrian in world frame&#34;  width=&#34;90%&#34;  /&gt;
  &lt;small&gt;
  &lt;b&gt;
     Qolo trajectory and tracked pedestrian in world frame
  &lt;/b&gt;
  &lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;In this work, we will create a dataset of mobile robot navigation around pedestrians from experimental data of a personal mobility device navigating autonomously around pedestrians in the streets of center Lausanne.&lt;/p&gt;

&lt;p&gt;The focus will be to assess people navigation behavior around the robot by extracting trajectories and motions. I aim to build a detecting, tracking, and motion profile extraction pipeline on lidar and camera data.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
  &lt;img src=&#34;./featured.png&#34; alt=&#34;dataset_qolo_overview&#34;  width=&#34;60%&#34;  /&gt;
  &lt;small&gt;
  &lt;b&gt;
    Overview of detected pedestrian from recorded rosbag and qolo robot
  &lt;/b&gt;
  &lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;single-sequence-evaluation&#34;&gt;Single sequence evaluation&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metrics&lt;/th&gt;
&lt;th&gt;Example&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Crowd characteristics&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;./crowd_density.png&#34; alt=&#34;dataset_qolo_overview&#34;  width=&#34;80%&#34;  /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Path efficiency&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;./qolo_path.png&#34; alt=&#34;qolo_path&#34;  width=&#34;70%&#34;  /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Shared control performance&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;./qolo_command.png&#34; alt=&#34;qolo_command&#34;  width=&#34;85%&#34;  /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;interclass-evaluation&#34;&gt;Interclass evaluation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;./comp_path.png&#34; alt=&#34;comp_path&#34;  width=&#34;85%&#34;  /&gt;&lt;/p&gt;

&lt;h2 id=&#34;dataset-and-toolkit-overview&#34;&gt;Dataset and toolkit overview&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Code available in &lt;a href=&#34;https://github.com/epfl-lasa/crowdbot-evaluation-tools&#34; target=&#34;_blank&#34;&gt;epfl-lasa/&lt;strong&gt;crowdbot-evaluation-tools&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;./single_frame_aggregate.jpg&#34; alt=&#34;single_frame_aggregate&#34;  width=&#34;95%&#34;  /&gt;
&lt;center&gt;
&lt;center&gt;
Trajectory of qolo with detected pedestrians
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MULLS: Versatile LiDAR SLAM via Multi-metric Linear Least Square</title>
      <link>https://yujie-he.github.io/publication/2021_mulls_icra/</link>
      <pubDate>Sun, 28 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2021_mulls_icra/</guid>
      <description>

&lt;h3 id=&#34;teaser&#34;&gt;Teaser&lt;/h3&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;./featured.png&#34; alt=&#34;MULLS&#34;  width=&#34;80%&#34;  /&gt;
&lt;small&gt;Pipeline of the multi-metric linear least square ICP&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;demo-video&#34;&gt;Demo video&lt;/h3&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;iframe width=&#34;600&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/85bGD55e3-0&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;details open&gt;
  &lt;summary&gt;&lt;b&gt;KITTI results&lt;/b&gt;&lt;/summary&gt;
&lt;div&gt;
  &lt;img src=&#34;https://github.com/YuePanEdward/MULLS/raw/main/assets/kitti_00_show.jpg&#34; alt=&#34;kitti_00_show&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/YuePanEdward/MULLS/raw/main/assets/kitti_01_show.jpg&#34; alt=&#34;kitti_01_show&#34; /&gt;
&lt;/div&gt;
&lt;/details&gt;&lt;/p&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;If you find this project is useful, you may cite it as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@inproceedings{Pan2021ICRA,
  title={{MULLS: Versatile LiDAR SLAM via Multi-metric Linear Least Square}},
  author={Pan, Yue and Xiao, Pengchuan and He, Yujie and Shao, Zhenlei and Li, Zesong},
  booktitle={Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021},
  pages={1-8}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>SLAM and Autonomous Navigation for Skid Steer Wheel Robot</title>
      <link>https://yujie-he.github.io/project/2018-hesai-internship/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2018-hesai-internship/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Robotics Algorithm Development Intern&lt;/strong&gt;, &lt;em&gt;Jul. 2018 - Aug. 2018&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Implemented sensor fusion between a 40-channel LiDAR, i.e., &lt;a href=&#34;https://www.hesaitech.com/pandora.html/Pandar40&#34; target=&#34;_blank&#34;&gt;Pandar40&lt;/a&gt; and gyroscope and achieved a 5% accuracy improvements on top of state-of-the-art SLAM framework and drew a 3D point cloud map of Tongji University Jiading Campus below 10m&lt;/li&gt;
&lt;li&gt;Deployed control, decision, and communication algorithms for a self-developed skid steer wheel robot, realizing autonomous navigation and obstacle avoidance in a $ 300 m^2 $ workspace&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;demos&#34;&gt;Demos&lt;/h2&gt;

&lt;p&gt;Examples of final mapping results can be seen as follows:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./tongjiFront_optimize.gif&#34; alt=&#34;tongjiFront_optimize&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./KWG_optimize.gif&#34; alt=&#34;KWG_optimize&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;
  &lt;strong&gt;Pointcloud Demo of Tongji Jiading Campus&lt;/br&gt;
  ðŸ‘‰ &lt;a href=&#34;https://goo.gl/maps/ygsUXZUryBs2RFw2A&#34; target=&#34;_blank&#34;&gt;Corresponding satellite map from Google map&lt;/a&gt;&lt;/strong&gt;&lt;/br&gt;
  Up: &lt;strong&gt;Main Gate&lt;/strong&gt;, Down: &lt;strong&gt;Kaiwu Building&lt;/strong&gt;
 &lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;misc&#34;&gt;Misc.&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./indoor-slam.jpg&#34; alt=&#34;indoor-slam-result&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt; &lt;strong&gt;Indoor SLAM @ Hesai Tech&lt;/strong&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./SSWR.jpg&#34; alt=&#34;algorithm-debugging&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt; &lt;strong&gt;Skid Steer Wheel Robot equipped with Pandar40 LiDAR&lt;/strong&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
