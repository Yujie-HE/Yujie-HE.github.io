<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Unmanned Aerial Vehicle on YUJIE HE</title>
    <link>https://yujie-he.github.io/tags/unmanned-aerial-vehicle/</link>
    <description>Recent content in Unmanned Aerial Vehicle on YUJIE HE</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Last updated on Oct., 2021 Â· Yujie HE &amp;copy; 2019 - 2021</copyright>
    <lastBuildDate>Thu, 17 Jun 2021 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://yujie-he.github.io/tags/unmanned-aerial-vehicle/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Development of vision based algorithms to a window/balcony drone delivery</title>
      <link>https://yujie-he.github.io/project/2021-lis-drone-delivery/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2021-lis-drone-delivery/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Semester Research Student&lt;/strong&gt; at &lt;a href=&#34;https://lis.epfl.ch/&#34; target=&#34;_blank&#34;&gt;Laboratory of Intelligent Systems (LIS)&lt;/a&gt;, EPFL since &lt;em&gt;Feb. 2021&lt;/em&gt;
Supervisor: &lt;a href=&#34;https://people.epfl.ch/valentin.wueest/?lang=en&#34; target=&#34;_blank&#34;&gt;Valentin WÃ¼est&lt;/a&gt; (PhD student), &lt;a href=&#34;https://people.epfl.ch/przemyslaw.kornatowski/?lang=en&#34; target=&#34;_blank&#34;&gt;Dr. Przemyslaw Mariusz Kornatowski&lt;/a&gt;, and &lt;a href=&#34;https://people.epfl.ch/dario.floreano&#34; target=&#34;_blank&#34;&gt;Prof. Dario Floreano&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;

&lt;p&gt;At the Laboratory of Intelligent Systems (LIS), passionate researchers are developing a human-friendly drone delivery system for last-cm delivery - &lt;a href=&#34;http://dronistics.epfl.ch&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Dronistics&lt;/strong&gt;&lt;/a&gt;. The system is composed of a safe drone called &lt;strong&gt;PackDrone&lt;/strong&gt; and software to control and monitor drones in real-time.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
  &lt;!-- &lt;img src=&#34;gearquad.jpg&#34; alt=&#34;gearquad_parcel&#34; style=&#34;zoom:12%;&#34; /&gt; --&gt;
  &lt;img src=&#34;https://dronistics.epfl.ch/img/PackDrone_deployed.jpg&#34; alt=&#34;PackDrone_deployed&#34;  width=&#34;200&#34;  /&gt;
  &lt;small&gt;
  &lt;b&gt;
    &lt;!-- Parcel placed above the cage allows the drone to transport parcels of various sizes without negative impact on lift --&gt;
     PackDrone can eliminate the damage from propellers or rotor blades with a foldable protective cage
  &lt;/b&gt;
  [Source: &lt;a href=&#34;http://dronistics.epfl.ch&#34; target=&#34;_blank&#34;&gt;Dronistics&lt;/a&gt;]
  &lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is the goal of this semester project?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our goal is to &lt;strong&gt;deliver to a balcony/window&lt;/strong&gt; which is &lt;strong&gt;tagged with a special symbol/pattern&lt;/strong&gt;. Moreover, the drone should be equipped with a system of &lt;strong&gt;collision avoidance&lt;/strong&gt; to prevent hitting a building.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why motivates us to work on this project?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One vivid example is that in this special period of Covid-19, people are required to keep social distance while delivery work keeps operating. In contrast to large aircraft, window/balcony delivery with lightweight drone is a reasonable and effective solution to send valuable parcels such as medical supplies rapidly and safely.&lt;/p&gt;

&lt;h2 id=&#34;system-architecture&#34;&gt;System architecture&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Illustration&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Hardware&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;./featured.jpg&#34; alt=&#34;experimental_drone&#34; width=&#34;600&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Software&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;./system_arch.jpg&#34; alt=&#34;system_arch&#34; width=&#34;600&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;center&gt;
  &lt;small&gt;
  &lt;b&gt;System architecture of the proposed drone delivery system&lt;/b&gt;
  &lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Visual fiducial marker evaluation
&lt;img src=&#34;./tag_evaluation.jpg&#34; alt=&#34;tag_evaluation&#34; width=&#34;600&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Onboard test&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;./tag_drone_real.png&#34; alt=&#34;tag_drone_real&#34; width=&#34;600&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;final-presentation&#34;&gt;Final presentation&lt;/h2&gt;

&lt;!-- &lt;iframe src=&#34;https://drive.google.com/file/d/1LCtTQ2NFRRjhwrPHcfao5ApY6hocKZaQ/preview&#34; width=&#34;700&#34; height=&#34;400&#34;&gt;&lt;/iframe&gt; --&gt;

&lt;iframe src=&#34;https://drive.google.com/file/d/1VmY0fp5KuiljASgDYkci4Nhcj0Mt3HlK/preview&#34; width=&#34;700&#34; height=&#34;400&#34;&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;code-videos&#34;&gt;Code &amp;amp; videos&lt;/h2&gt;

&lt;p&gt;ðŸš§ To be updated!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Autonomous Navigation and Landing for Crazyflie</title>
      <link>https://yujie-he.github.io/project/2021-crazyflie-auto-nav/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2021-crazyflie-auto-nav/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Final project&lt;/strong&gt; in &lt;a href=&#34;https://edu.epfl.ch/coursebook/fr/aerial-robotics-MICRO-502&#34; target=&#34;_blank&#34;&gt;MICRO-502 Aerial robotics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Members: Yujie He, &lt;a href=&#34;https://github.com/Jianhao-zheng/&#34; target=&#34;_blank&#34;&gt;Jianhao Zheng&lt;/a&gt;, and &lt;a href=&#34;https://github.com/kevinxqiu&#34; target=&#34;_blank&#34;&gt;Longlai Qiu&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lecturer:  &lt;a href=&#34;https://people.epfl.ch/dario.floreano/?lang=en&#34; target=&#34;_blank&#34;&gt;Prof. Dario Floreano&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;goal-autonomous-navigation-and-landing-for-crazyflie&#34;&gt;Goal: Autonomous Navigation and Landing for Crazyflie&lt;/h2&gt;

&lt;p&gt;In this practical, we programed based on &lt;a href=&#34;https://www.bitcraze.io/products/crazyflie-2-1/&#34; target=&#34;_blank&#34;&gt;Crazyflie 2.1&lt;/a&gt; to find and precisely land on a platform with height of 10 cm by utilizing z reading from &lt;a href=&#34;https://www.bitcraze.io/products/flow-deck-v2/&#34; target=&#34;_blank&#34;&gt;flow deck&lt;/a&gt;. Additionally, We also utilized sensor readings from &lt;a href=&#34;https://www.bitcraze.io/products/multi-ranger-deck/&#34; target=&#34;_blank&#34;&gt;multi-ranger deck&lt;/a&gt; to avoid the obstacles presented in the environment.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/blob/master/pics/cover.jpg&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/raw/master/pics/cover.jpg&#34; alt=&#34;cover&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;pipeline&#34;&gt;Pipeline&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Autonomous navigation &amp;amp; landing&lt;/th&gt;
&lt;th&gt;Workflow&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;âœ“ Local obstacle avoidance &lt;br&gt;âœ“ Grid-based coverage path planning &lt;br&gt;âœ“ Waypoint following &lt;br&gt;âœ“ A* search-based re-planning&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/master/pics/pipeline_final.png&#34; alt=&#34;pipeline_final&#34;  width=&#34;500&#34;/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;

&lt;h3 id=&#34;features&#34;&gt;Features&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Modular library for different tasks&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;â”œâ”€â”€ cf_load_params.py  # parameter setting
â”œâ”€â”€ cf_search.py       # searching functions such as, coverage planning, box edge detection, A* search
â”œâ”€â”€ cf_state_class.py  # state estimation class for the proposed task
â””â”€â”€ cf_utilis.py       # utility functions, such as live plotting
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Utilized &lt;code&gt;argparse&lt;/code&gt; for quick parameter adjustment and tuning&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Utilized &lt;code&gt;matplotlib&lt;/code&gt; for real-time visualization&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;structure&#34;&gt;Structure&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Code folder: &lt;a href=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/tree/master/code/crazyflie-lib-python/group_7&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;./code/crazyflie-lib-python/group_7/&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;.
â”œâ”€â”€ cf_load_params.py
â”œâ”€â”€ cf_search.py
â”œâ”€â”€ cf_state_class.py
â”œâ”€â”€ cf_utilis.py
â”œâ”€â”€ overall.py
â”œâ”€â”€ draw_traj_demo.py
â”œâ”€â”€ logs
â”‚   â”œâ”€â”€ overall-20210530_1930_x.csv
â”‚   â”œâ”€â”€ overall-20210530_1930_x_half.csv
â”‚   â”œâ”€â”€ overall-20210530_1930_y.csv
â”‚   â””â”€â”€ overall-20210530_1930_y_half.cs
â””â”€â”€ readme.md
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;demo&#34;&gt;Demo&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;overall.py&lt;/code&gt;: overall pipeline from taking off to landing.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# -x (float) for setting initial x position
# -y (float) for setting initial y position
# -v (bool) for enabling visualization
python overall.py -x 0.6 -y 0.6 -v
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/blob/master/pics/cf_land.gif&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/raw/master/pics/cf_land.gif&#34; alt=&#34;cf_land&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;draw_traj.py&lt;/code&gt;: x-y trajectory visualization with region annotation&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# --log_folder (str) for assigning input log folder
# --logname (str) for loding log file
# --img_folder (str) for assigning output image folder
# -n/--name (str) for assigning output image name
# --zone_anno (bool) for enabling region annotation
python draw_traj_demo.py --logname overall-20210530_1930 -n cf_demo --zone_anno
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/blob/master/pics/cf_demo.png&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/raw/master/pics/cf_demo.png&#34; alt=&#34;cf_demo&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The estimated values drift considerably after long flights. Moreover, the predicted starting position is significantly different from the starting point after the drone re-takes off.&lt;/p&gt;

&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Features&lt;/th&gt;
&lt;th&gt;Figures&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;âœ“ Size: 480 cm (W) Ã— 120 cm (H) &lt;/br&gt;âœ“ Starting &amp;amp; Landing pad&lt;/br&gt; - starting (x, y) = (60 cm, 60 cm)&lt;/br&gt; - landing pad randomly placed &lt;/br&gt;âœ“ Circular and rectangular obstacles&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hibetterheyj/Crazyflie_Auto_Navigation_Landing/master/pics/experimental_setup.png&#34; alt=&#34;experimental_setup&#34;  width=&#34;500&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;iframe width=&#34;560&#34; height=&#34;320&#34; src=&#34;https://www.youtube.com/embed/RP4-SlhOIUk&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;slide&#34;&gt;Slide&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;
&lt;iframe src=&#34;https://drive.google.com/file/d/1vY_UMflVXOcUSOASHkGHsSTXCBmwrVhK/preview&#34; width=&#34;560&#34; height=&#34;320&#34;&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Online Visual Object Tracking for UAV in Dynamic Environments</title>
      <link>https://yujie-he.github.io/project/2020-tracking4uav/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2020-tracking4uav/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Undergraduate Research Assistant&lt;/strong&gt; since &lt;em&gt;Sep. 2018&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Investigated correlation filter (CF)-based &lt;strong&gt;visual object tracking&lt;/strong&gt; for unmanned aerial vehicles. By applying &lt;strong&gt;machine learning &amp;amp; deep learning&lt;/strong&gt; techniques, we have improved the existing trackers on overall tracking performance in challenging scenarios with real-time operational capability.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;papers-with-code&#34;&gt;Papers with code&lt;/h2&gt;

&lt;p&gt;Related work has been published in journals and conferences as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Proposed a lightweight and generalizable &lt;strong&gt;triple attention strategy&lt;/strong&gt; on CF-based framework by exploiting mutual independence of the appearance model and feature responses to implement real-time tracking for UAV.&lt;/p&gt;

&lt;p&gt;ðŸš© &lt;a href=&#34;../../publication/2020_tacf_iros/&#34;&gt;&lt;em&gt;Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters&lt;/em&gt;&lt;/a&gt; in &lt;strong&gt;IROS 2020&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Employed the adaptive &lt;strong&gt;GMSD-based context analysis&lt;/strong&gt; and &lt;strong&gt;dynamic weighted filters&lt;/strong&gt; for utilizing both contextual and historical information, and leveraged &lt;strong&gt;lightweight convolution features&lt;/strong&gt; to efficiently raise the tracking robustness.&lt;/p&gt;

&lt;p&gt;ðŸš© &lt;a href=&#34;../../publication/2020_mkct_ncaa/&#34;&gt;&lt;em&gt;Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters&lt;/em&gt;&lt;/a&gt; in &lt;strong&gt;Neural Computing and Applications&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Exploited the inter-frame information between prediction and backtracking phases for further incorporating the &lt;strong&gt;bidirectional incongruity error&lt;/strong&gt; into the CF learning.&lt;/p&gt;

&lt;p&gt;ðŸš© &lt;a href=&#34;../../publication/2020_bicf_icra/&#34;&gt;&lt;em&gt;BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking&lt;/em&gt;&lt;/a&gt; in &lt;strong&gt;ICRA 2020&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For more info, please refer to my &lt;a href=&#34;https://www.youtube.com/channel/UCGpK01NL0j3RkXpsODXm-Dg&#34; target=&#34;_blank&#34;&gt;YouTube channel&lt;/a&gt; and &lt;a href=&#34;https://github.com/hibetterheyj&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
