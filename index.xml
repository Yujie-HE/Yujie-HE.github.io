<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>YUJIE HE</title>
    <link>https://yujie-he.github.io/</link>
    <description>Recent content on YUJIE HE</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Last updated on Nov, 2020 ¬∑ Yujie HE &amp;copy; 2019 - 2020</copyright>
    <lastBuildDate>Wed, 07 Oct 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://yujie-he.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Overview</title>
      <link>https://yujie-he.github.io/study/2019-deep-learning/final_project/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/study/2019-deep-learning/final_project/</guid>
      <description>

&lt;h3 id=&#34;final-project&#34;&gt;Final Project&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;üí•Online Viewer: &lt;a href=&#34;https://nbviewer.jupyter.org/github/hibetterheyj/tju_deep_learning/blob/master/final_project/HYJ_DL_0108.ipynb&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;jupyter notebook for final project&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Enhanced 3D Zonal Segmentation of the Prostate on MRI via Enhanced Weight-Standardization and GroupNorm&lt;/p&gt;

&lt;p&gt;Âü∫‰∫éÁöÑWeight-StandardizationÂíåGroupNormÁöÑ‰∏âÁª¥ÂâçÂàóËÖ∫MRIÂå∫ÂùóÂàÜÂâ≤&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this final project, I utilized Weight Standardization (WS) as well as GroupNorm to accelerate neural networks training and improve overall segmentation results for 3D Zonal Segmentation of the Prostate on MRI images. WS is targeted at the micro-batch training setting where each GPU typically has only 1-2 images for training. The quantitative experiments have shown that UWG-Net can outperform the performances of 3D U-Net (baseline) with BN trained with small batch sizes with only two more lines of code. The effectiveness of WS is verified on the open-source Prostate Dataset, including 22 training cases and 10 testing cases.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://yujie-he.github.io/img/study/tju_dl_project_result.png&#34; alt=&#34;Quantitative experiments on Prostate Dataset&#34; /&gt;
&lt;small&gt;Quantitative experiments on Prostate Dataset. &lt;font color=&#34;red&#34;&gt;Red&lt;/font&gt;, &lt;font color=&#34;green&#34;&gt;green&lt;/font&gt;, and &lt;font color=&#34;blue&#34;&gt;blue&lt;/font&gt; fonts denote the first, second, and third best performance among all models. &lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Disruptor-Aware Interval-Based Response Inconsistency for Correlation Filters in Real-Time Aerial Tracking</title>
      <link>https://yujie-he.github.io/publication/2020-ibri-tgrs/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2020-ibri-tgrs/</guid>
      <description>&lt;!--

&lt;center&gt;

![BiCF_comp](featured.png)
&lt;small&gt;Comparison between discriminative correlation filter (DCF) and the proposed BiCF&lt;/small&gt;

&lt;/center&gt;

### Reference

If you find this project is useful, you may cite it as:

```tex
@article{Lin2020TCSVT,
	title={{Learning Temporary Block-Based Bidirectional Incongruity-Aware Correlation Filters for Efficient UAV Object Tracking}},
	author={Lin, Fuling and Fu, Changhong and He, Yujie and Guo, Fuyu and Tang, Qian},
	booktitle={IEEE Transactions on Circuits and Systems for Video Technology},
	pages={1-14},
	year={2020}
}

```

--&gt;
</description>
    </item>
    
    <item>
      <title>Learning Temporary Block-Based Bidirectional Incongruity-Aware Correlation Filters for Efficient UAV Object Tracking</title>
      <link>https://yujie-he.github.io/publication/2020-tbbicf-tcsvt/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2020-tbbicf-tcsvt/</guid>
      <description>

&lt;!--

&lt;center&gt;

![BiCF_comp](featured.png)
&lt;small&gt;Comparison between discriminative correlation filter (DCF) and the proposed BiCF&lt;/small&gt;

&lt;/center&gt;

--&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;If you find this project is useful, you may cite it as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@article{Lin2020TCSVT,
	title={{Learning Temporary Block-Based Bidirectional Incongruity-Aware Correlation Filters for Efficient UAV Object Tracking}},
	author={Lin, Fuling and Fu, Changhong and He, Yujie and Guo, Fuyu and Tang, Qian},
	booktitle={IEEE Transactions on Circuits and Systems for Video Technology},
	pages={1-14},
	year={2020}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters</title>
      <link>https://yujie-he.github.io/publication/2020_tacf_iros/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2020_tacf_iros/</guid>
      <description>

&lt;!--
![TACF](featured.jpg)
&lt;small&gt;Comparison between baseline KCC tracker and the proposed TACF tracker&lt;/small&gt;
--&gt;

&lt;h3 id=&#34;videos&#34;&gt;Videos&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Presentation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/XlFgz8h4dts&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tracking results demo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/4IWKLmRoS38&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;If you find this project is useful, you may cite it as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@inproceedings{He2020IROS,
	title={{Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters}},
	author={He, Yujie and Fu, Changhong and Lin, Fuling and Li, Yiming and Lu, Peng},
	booktitle={Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS)},
	year={2020},
	pages={1575-1582}
 }
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Online Visual Object Tracking for UAV in Dynamic Environments</title>
      <link>https://yujie-he.github.io/project/2020-tracking4uav/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2020-tracking4uav/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Undergraduate Research Assistant&lt;/strong&gt; since &lt;em&gt;Sep. 2018&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Investigated correlation filter (CF)-based &lt;strong&gt;visual object tracking&lt;/strong&gt; for unmanned aerial vehicles. By applying &lt;strong&gt;machine learning &amp;amp; deep learning&lt;/strong&gt; techniques, we have improved the existing trackers on overall tracking performance in challenging scenarios with real-time operational capability.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;papers-with-code&#34;&gt;Papers with code&lt;/h2&gt;

&lt;p&gt;Related work has been published in journals and conferences as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Proposed a lightweight and generalizable &lt;strong&gt;triple attention strategy&lt;/strong&gt; on CF-based framework by exploiting mutual independence of the appearance model and feature responses to implement real-time tracking for UAV.&lt;/p&gt;

&lt;p&gt;üö© &lt;a href=&#34;../../publication/2020_tacf_iros/&#34;&gt;&lt;em&gt;Towards Robust Visual Tracking for Unmanned Aerial Vehicle with Tri-Attentional Correlation Filters&lt;/em&gt;&lt;/a&gt; in &lt;strong&gt;IROS 2020&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Employed the adaptive &lt;strong&gt;GMSD-based context analysis&lt;/strong&gt; and &lt;strong&gt;dynamic weighted filters&lt;/strong&gt; for utilizing both contextual and historical information, and leveraged &lt;strong&gt;lightweight convolution features&lt;/strong&gt; to efficiently raise the tracking robustness.&lt;/p&gt;

&lt;p&gt;üö© &lt;a href=&#34;../../publication/2020_mkct_ncaa/&#34;&gt;&lt;em&gt;Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters&lt;/em&gt;&lt;/a&gt; in &lt;strong&gt;Neural Computing and Applications&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Exploited the inter-frame information between prediction and backtracking phases for further incorporating the &lt;strong&gt;bidirectional incongruity error&lt;/strong&gt; into the CF learning.&lt;/p&gt;

&lt;p&gt;üö© &lt;a href=&#34;../../publication/2020_bicf_icra/&#34;&gt;&lt;em&gt;BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking&lt;/em&gt;&lt;/a&gt; in &lt;strong&gt;ICRA 2020&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For more info, please refer to my &lt;a href=&#34;https://www.youtube.com/channel/UCGpK01NL0j3RkXpsODXm-Dg&#34; target=&#34;_blank&#34;&gt;YouTube channel&lt;/a&gt; and &lt;a href=&#34;https://github.com/hibetterheyj&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking</title>
      <link>https://yujie-he.github.io/publication/2020_bicf_icra/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2020_bicf_icra/</guid>
      <description>

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;BiCF_comp&#34; /&gt;
&lt;small&gt;Comparison between discriminative correlation filter (DCF) and the proposed BiCF&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;If you find this project is useful, you may cite it as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@inproceedings{Lin2020ICRA,
	title={{BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking}},
	author={Lin, Fuling and Fu, Changhong and He, Yujie and Guo, Fuyu and Tang, Qian},
	booktitle={Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
	pages={2365-2371},
	year={2020}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Jan 2020: Our paper BiCF to appear at ICRA 2020, Paris, France.</title>
      <link>https://yujie-he.github.io/post/20-01-bicf/</link>
      <pubDate>Wed, 22 Jan 2020 12:00:00 +0800</pubDate>
      
      <guid>https://yujie-he.github.io/post/20-01-bicf/</guid>
      <description>&lt;p&gt;Our paper &lt;a href=&#34;https://yujie-he.github.io/publication/2020_bicf_icra/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;BiCF: Learning Bidirectional Incongruity-Aware Correlation Filter for Efficient UAV Object Tracking&lt;/em&gt;&lt;/a&gt; is accepted by IEEE/RSJ International Conference on Robotics and Automation, 2020 !&lt;/p&gt;

&lt;p&gt;It is my first time to publish a regular paper in top robotics conference. More details will be released soon !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3D Zonal Segmentation of the Prostate MRI (Deep Learning Final Project)</title>
      <link>https://yujie-he.github.io/project/2019-dl-mip/</link>
      <pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2019-dl-mip/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Final project for TJ-100685 Ê∑±Â∫¶Â≠¶‰π† | Deep learning&lt;/strong&gt;, &lt;em&gt;Sep. 2019 - Jan. 2020&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Utilized the latest &lt;strong&gt;Weight Standardization&lt;/strong&gt;}** (WS) as well as &lt;strong&gt;GroupNorm&lt;/strong&gt; to accelerate neural networks training from scratch for 3D Zonal Segmentation of the &lt;strong&gt;Prostate MRI images&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Conducted extensive evaluation between the proposed UWG-Net with the baseline with &lt;strong&gt;small batch sizes&lt;/strong&gt;, achieving 2-3\% increase in &lt;strong&gt;multi-class segmentation accuracy&lt;/strong&gt; for medical imaging application.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more info, you can refer to this &lt;a href=&#34;https://yujie-he.github.io/study/2019-deep-learning/final_project/&#34; target=&#34;_blank&#34;&gt;page&lt;/a&gt; !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jan 2020: Our paper MKCT to appear at Neural Computing and Applications.</title>
      <link>https://yujie-he.github.io/post/20-01-ncaa/</link>
      <pubDate>Mon, 06 Jan 2020 12:00:00 +0800</pubDate>
      
      <guid>https://yujie-he.github.io/post/20-01-ncaa/</guid>
      <description>&lt;p&gt;Our paper &lt;a href=&#34;https://yujie-he.github.io/publication/2020_mkct_ncaa/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters&lt;/em&gt;&lt;/a&gt; is accepted by the journal of &lt;strong&gt;Neural Computing and Applications&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;It is my first time to publish a regular paper as the first student author. More details will be released soon!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters</title>
      <link>https://yujie-he.github.io/publication/2020_mkct_ncaa/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2020_mkct_ncaa/</guid>
      <description>

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;MKCT_workflow&#34; /&gt;
&lt;small&gt;Main structure of the proposed tracking approach&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;If you find this project is useful, you may cite it as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;@article{Fu2020NCAA,
	title={{Robust Multi-Kernelized Correlators for UAV Tracking with Adaptive Context Analysis and Dynamic Weighted Filters}},
	author={Fu, Changhong and He, Yujie and Lin, Fuling and Xiong, Weijiang},
	journal={Neural Computing and Applications},
	pages={1-17},
	year={2020}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Nov 2019: Our paper SPCF won the Best Poster Award in the IROS Workshop, Macua, China.</title>
      <link>https://yujie-he.github.io/post/19-11-iros/</link>
      <pubDate>Mon, 04 Nov 2019 12:00:00 +0800</pubDate>
      
      <guid>https://yujie-he.github.io/post/19-11-iros/</guid>
      <description>&lt;p&gt;First time to participate the top robotics conference&amp;mdash;IEEE/RSJ International Conference on Intelligent Robots and Systems (&lt;a href=&#34;https://www.iros2019.org/&#34; target=&#34;_blank&#34;&gt;IROS 2019&lt;/a&gt;) held on Nov. 4 ‚Äì 8, 2019 in Macau, China.&lt;/p&gt;

&lt;p&gt;Feel very lucky to talk to the experts, professors, and my fellows!&lt;/p&gt;

&lt;p&gt;Our paper &amp;lsquo;Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features&amp;rsquo; is accepted by the &lt;a href=&#34;http://www.robomai.com/&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Workshop on Fast Neural Perception and Learning for Intelligent Vehicles and Robotics&lt;/strong&gt;&lt;/a&gt; and won the &lt;strong&gt;Best Poster Award&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;For more details, please refer to &lt;a href=&#34;https://yujie-he.github.io/publication/2019_spcf_irosw/&#34; target=&#34;_blank&#34;&gt;SPCF&lt;/a&gt;!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./1911-IROS-portrait.jpg&#34; alt=&#34;IROS2019&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;My first time to attend top robotics conference, IROS @ Macau&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;!--

![Keynote](https://media.licdn.cn/dms/image/C5122AQG55FDTtcTyPQ/feedshare-shrink_2048_1536/0?e=1579132800&amp;v=beta&amp;t=QtgkGH1xUXjemrQ3UEbf5WVUad9FIm0XWVy_g4rp4xk)

&lt;small&gt; Keynote by *Davide Scaramuzza* covering Autonomous Drones Event Cameras &lt;/small&gt;

--&gt;
</description>
    </item>
    
    <item>
      <title>Sample Purification-Aware Correlation Filters for UAV Tracking with Cooperative Deep Features</title>
      <link>https://yujie-he.github.io/publication/2019_spcf_irosw/</link>
      <pubDate>Sat, 31 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/publication/2019_spcf_irosw/</guid>
      <description>&lt;hr /&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;featured.png&#34; alt=&#34;SPCF_comp&#34; /&gt;
&lt;small&gt;Comparison between traditional CF-based and proposed SPCF tracker&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teaching Assistant in Open Source Hardware and Programming</title>
      <link>https://yujie-he.github.io/project/2019-tongji-ta/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2019-tongji-ta/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Teaching Assistant&lt;/strong&gt;, &lt;em&gt;Sep. 2018 - Jan. 2019&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Assisted first-year students major in Industrial Design to get started Arduino Hardware and Programming&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Designed a series of the electromechanical modules for Industrial Design students&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Gave lectures on basic mechanical principle with Arduino hardware and programming and advanced RGBD sensors for the semester project&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following video is &lt;strong&gt;Mechatronics Module Experiments&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;iframe width=&#34;645&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/gTo2n-7T-Ao&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DIAN Racing Formula Student Electric Team</title>
      <link>https://yujie-he.github.io/project/2018-dian-racing/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2018-dian-racing/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Powertrain Group Leader&lt;/strong&gt;, &lt;em&gt;Sep. 2016 - Dec. 2018&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Designed and optimized the overall powertrain system to ensure China&amp;rsquo;s first leading four-wheel-drive Formula Student Racecar, achieving an 8\% efficiency and 10\% lightweight improvement&lt;/li&gt;
&lt;li&gt;Participated FSEC 2017 - 2018 and SFJ 2018 as Chief Powertrain Engineer, contributing to DIAN Racing‚Äòs win in first place in Engineering Design and Efficiency Prize, and Best Powertrain Award from 2017 to 2018&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following video is &lt;strong&gt;virtual assembly of DRe18&lt;/strong&gt;Ôºåwhich was what I worked for as Powertrain Group Leader.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;iframe width=&#34;645&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/bWmHDvBw1qw&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;./design-report-FSEC19.jpg&#34; alt=&#34;design-report-FSEC19&#34; /&gt;
&lt;small&gt; &lt;strong&gt;Design Report Final @ FSEC19&lt;/strong&gt;&lt;/small&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SLAM and Autonomous Navigation for Skid Steer Wheel Robot</title>
      <link>https://yujie-he.github.io/project/2018-hesai-internship/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2018-hesai-internship/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Robotics Algorithm Development Intern&lt;/strong&gt;, &lt;em&gt;Jul. 2018 - Aug. 2018&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;h2&gt;Table of Contents&lt;/h2&gt;
HAHAHUGOSHORTCODE-TOC0-HBHB&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Implemented sensor fusion between a 40-channel LiDAR, i.e., &lt;a href=&#34;https://www.hesaitech.com/pandora.html/Pandar40&#34; target=&#34;_blank&#34;&gt;Pandar40&lt;/a&gt; and gyroscope and achieved a 5% accuracy improvements on top of state-of-the-art SLAM framework and drew a 3D point cloud map of Tongji University Jiading Campus below 10m&lt;/li&gt;
&lt;li&gt;Deployed control, decision, and communication algorithms for a self-developed skid steer wheel robot, realizing autonomous navigation and obstacle avoidance in a $ 300 m^2 $ workspace&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;demos&#34;&gt;Demos&lt;/h2&gt;

&lt;p&gt;Examples of final mapping results can be seen as follows:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./tongjiFront_optimize.gif&#34; alt=&#34;tongjiFront_optimize&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./KWG_optimize.gif&#34; alt=&#34;KWG_optimize&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;
  &lt;strong&gt;Pointcloud Demo of Tongji Jiading Campus&lt;/br&gt;
  üëâ &lt;a href=&#34;https://goo.gl/maps/ygsUXZUryBs2RFw2A&#34; target=&#34;_blank&#34;&gt;Corresponding satellite map from Google map&lt;/a&gt;&lt;/strong&gt;&lt;/br&gt;
  Up: &lt;strong&gt;Main Gate&lt;/strong&gt;, Down: &lt;strong&gt;Kaiwu Building&lt;/strong&gt;
 &lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;misc&#34;&gt;Misc.&lt;/h2&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./indoor-slam.jpg&#34; alt=&#34;indoor-slam-result&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt; &lt;strong&gt;Indoor SLAM @ Hesai Tech&lt;/strong&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./SSWR.jpg&#34; alt=&#34;algorithm-debugging&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt; &lt;strong&gt;Skid Steer Wheel Robot equipped with Pandar40 LiDAR&lt;/strong&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Super Power Robot Team</title>
      <link>https://yujie-he.github.io/project/2018-super-power/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yujie-he.github.io/project/2018-super-power/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Project Manager &amp;amp; Mechanical Development Leader&lt;/strong&gt;, &lt;em&gt;Oct. 2016 - Jun. 2018&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Designed two main robots to participate in national mobile robot competition, RoboMaster, achieving lightweight and stability of the chassis and 3DOF pan-tilt mechanism and multi-robot interaction&lt;/li&gt;
&lt;li&gt;Optimized structural design to enhance operation stability and achieve lightweight, enable the robots flexible operation and combating under complicated circumstances&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
